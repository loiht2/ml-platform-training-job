# Backend Algorithm Update - JSON Configuration Format

## Version: kubeflow-v1.2
**Date**: November 30, 2025

---

## Summary

Updated the backend to pass the entire training configuration as a **single JSON object** in the `TRAINING_CONFIG` environment variable, instead of converting each parameter to individual environment variables.

---

## Changes Made

### Before (v1.1)
The backend converted each parameter to a separate environment variable:

```yaml
spec:
  runtimeEnvYAML: |
    env_vars:
      NUM_WORKER: "2"
      USE_GPU: "false"
      LABEL_COLUMN: "target"
      RUN_NAME: "xgboost-iris-test"
      STORAGE_PATH: "/home/ray/result-storage"
      S3_ENDPOINT: "http://minio.example.com"
      S3_ACCESS_KEY: "loiht2"
      S3_SECRET_KEY: "..."
      S3_REGION: "us-east-1"
      S3_BUCKET: "training-data"
      S3_TRAIN_KEY: "iris/train.csv"
      NUM_BOOST_ROUND: "100"
      EARLY_STOPPING_ROUNDS: "10"
      ETA: "0.3"
      GAMMA: "0.0"
      MAX_DEPTH: "6"
      # ... 40+ more environment variables
```

**Problems**:
- Hard-coded parameter names
- Difficult to maintain
- Container needs to parse 50+ environment variables
- Complex logic for optional parameters

### After (v1.2)
The backend creates a single JSON configuration:

```yaml
spec:
  runtimeEnvYAML: |
    env_vars:
      TRAINING_CONFIG: |
        {
          "num_worker": 2,
          "use_gpu": false,
          "label_column": "target",
          "run_name": "xgboost-iris-test",
          "storage_path": "/home/ray/result-storage",
          "s3": {
            "endpoint": "http://minio.example.com",
            "access_key": "loiht2",
            "secret_key": "...",
            "region": "us-east-1",
            "bucket": "training-data",
            "train_key": "iris/train.csv"
          },
          "xgboost": {
            "num_boost_round": 100,
            "early_stopping_rounds": 10,
            "eta": 0.3,
            "gamma": 0.0,
            "max_depth": 6,
            "min_child_weight": 1.0,
            "subsample": 1.0,
            "colsample_bytree": 1.0,
            "lambda": 1.0,
            "alpha": 0.0,
            "tree_method": "auto",
            "objective": "reg:squarederror",
            "eval_metric": ["rmse", "mae"]
            # ... all other parameters
          }
        }
```

**Benefits**:
- ‚úÖ Single environment variable to read
- ‚úÖ Native JSON structure (easy to parse)
- ‚úÖ Hierarchical organization (s3, xgboost, custom sections)
- ‚úÖ Container can use standard JSON parser
- ‚úÖ Extensible for new algorithms
- ‚úÖ Type-safe (numbers are numbers, booleans are booleans)

---

## Configuration Structure

The JSON configuration has the following structure:

```json
{
  // Training control
  "num_worker": <int>,
  "use_gpu": <bool>,
  "label_column": <string>,
  "run_name": <string>,
  "storage_path": <string>,
  
  // S3/MinIO configuration
  "s3": {
    "endpoint": <string>,
    "access_key": <string>,
    "secret_key": <string>,
    "region": <string>,
    "bucket": <string>,
    "train_key": <string>,
    "val_key": <string>  // optional
  },
  
  // Algorithm-specific hyperparameters
  "xgboost": {
    "num_boost_round": <int>,
    "early_stopping_rounds": <int>,
    "eta": <float>,
    "max_depth": <int>,
    // ... all XGBoost parameters
  },
  
  // Custom hyperparameters (for custom algorithms)
  "custom": {
    "<key>": <value>,
    ...
  }
}
```

---

## Container Implementation

Your training container should read the configuration like this:

### Python Example

```python
import json
import os

# Read TRAINING_CONFIG environment variable
config_str = os.environ.get('TRAINING_CONFIG', '{}')
config = json.loads(config_str)

# Access configuration values
num_workers = config.get('num_worker', 1)
use_gpu = config.get('use_gpu', False)
run_name = config.get('run_name', 'default')

# Access S3 configuration
s3_config = config.get('s3', {})
s3_endpoint = s3_config.get('endpoint')
s3_bucket = s3_config.get('bucket')
s3_train_key = s3_config.get('train_key')

# Access XGBoost hyperparameters
xgb_config = config.get('xgboost', {})
num_boost_round = xgb_config.get('num_boost_round', 100)
eta = xgb_config.get('eta', 0.3)
max_depth = xgb_config.get('max_depth', 6)

print(f"Training {run_name} with {num_workers} workers")
print(f"XGBoost params: eta={eta}, max_depth={max_depth}")
```

### Go Example

```go
package main

import (
    "encoding/json"
    "os"
)

type Config struct {
    NumWorker    int              `json:"num_worker"`
    UseGPU       bool             `json:"use_gpu"`
    RunName      string           `json:"run_name"`
    S3           S3Config         `json:"s3"`
    XGBoost      XGBoostConfig    `json:"xgboost"`
}

type S3Config struct {
    Endpoint   string `json:"endpoint"`
    Bucket     string `json:"bucket"`
    TrainKey   string `json:"train_key"`
}

type XGBoostConfig struct {
    NumBoostRound int     `json:"num_boost_round"`
    Eta           float64 `json:"eta"`
    MaxDepth      int     `json:"max_depth"`
}

func main() {
    configStr := os.Getenv("TRAINING_CONFIG")
    
    var config Config
    if err := json.Unmarshal([]byte(configStr), &config); err != nil {
        panic(err)
    }
    
    // Use configuration
    fmt.Printf("Training %s with %d workers\n", config.RunName, config.NumWorker)
}
```

---

## Code Changes

### Files Modified

1. **backend/converter/converter.go**
   - Added `encoding/json` import
   - Replaced `buildRuntimeEnvYAML()` method
   - Added `buildTrainingConfig()` method
   - Added `buildXGBoostConfig()` method
   - Removed `appendXGBoostHyperparameters()` method

2. **backend/converter/converter_test.go** (NEW)
   - Test for JSON configuration generation
   - Validates structure and format

3. **backend/converter/rayjob_test.go** (NEW)
   - End-to-end test showing complete RayJob YAML
   - Demonstrates the final output format

---

## Testing

### Unit Tests

```bash
cd backend

# Test JSON config generation
go test -v ./converter -run TestBuildRuntimeEnvYAML

# Test complete RayJob conversion
go test -v ./converter -run TestConvertToRayJobV2WithJSONConfig
```

Both tests pass and show the generated output.

### Integration Test

1. **Submit a job through the UI**:
   - Login to Kubeflow: `http://192.168.40.246:32269`
   - Navigate to Training Jobs
   - Click "Create Training Job"
   - Fill in the form:
     - Job Name: `test-json-config`
     - Algorithm: XGBoost
     - Configure data sources
   - Click Submit

2. **Verify RayJob was created**:
   ```bash
   kubectl get rayjobs -n admin
   kubectl get rayjob test-json-config -n admin -o yaml
   ```

3. **Check the runtimeEnvYAML section**:
   ```bash
   kubectl get rayjob test-json-config -n admin -o yaml | grep -A 100 "runtimeEnvYAML"
   ```

   Should show:
   ```yaml
   runtimeEnvYAML: |
     env_vars:
       TRAINING_CONFIG: |
         {
           "num_worker": 2,
           "xgboost": {
             ...
           }
         }
   ```

4. **Verify container receives the config**:
   ```bash
   # Get pod name
   kubectl get pods -n admin -l ray.io/cluster=test-json-config
   
   # Check environment variables
   kubectl exec -n admin <pod-name> -c ray-head -- env | grep TRAINING_CONFIG
   ```

---

## Deployment

```bash
# Build
cd backend
docker build -t loihoangthanh1411/ml-platform-backend:kubeflow-v1.2 .

# Push
docker push loihoangthanh1411/ml-platform-backend:kubeflow-v1.2

# Deploy
kubectl set image deployment/ml-platform-backend -n kubeflow \
  backend=loihoangthanh1411/ml-platform-backend:kubeflow-v1.2

# Verify
kubectl get pods -n kubeflow -l app=ml-platform,component=backend
kubectl get deployment ml-platform-backend -n kubeflow -o jsonpath='{.spec.template.spec.containers[0].image}'
```

**Current Status**: ‚úÖ Deployed and running

---

## Migration Guide

If you have existing training containers that expect individual environment variables, you need to update them to read from `TRAINING_CONFIG`.

### Quick Migration

Add this wrapper function to your training script:

```python
import json
import os

def get_config():
    """Read configuration from TRAINING_CONFIG or fall back to individual env vars"""
    config_str = os.environ.get('TRAINING_CONFIG')
    
    if config_str:
        # New format: JSON config
        return json.loads(config_str)
    else:
        # Old format: individual env vars (for backward compatibility)
        return {
            'num_worker': int(os.getenv('NUM_WORKER', '1')),
            'use_gpu': os.getenv('USE_GPU', 'false').lower() == 'true',
            'run_name': os.getenv('RUN_NAME', 'default'),
            'storage_path': os.getenv('STORAGE_PATH', '/tmp'),
            's3': {
                'endpoint': os.getenv('S3_ENDPOINT'),
                'bucket': os.getenv('S3_BUCKET'),
                'train_key': os.getenv('S3_TRAIN_KEY'),
            },
            'xgboost': {
                'num_boost_round': int(os.getenv('NUM_BOOST_ROUND', '100')),
                'eta': float(os.getenv('ETA', '0.3')),
                'max_depth': int(os.getenv('MAX_DEPTH', '6')),
                # ... etc
            }
        }

# Use it
config = get_config()
```

---

## Benefits

### For Backend Developers
- **Simpler code**: One method instead of 70+ lines of string concatenation
- **Type safety**: JSON handles type conversions automatically
- **Maintainable**: Easy to add new parameters or algorithms
- **Testable**: Easy to verify the generated JSON

### For Container Developers
- **Standard format**: Use any JSON parser in any language
- **Single source of truth**: One env var to read
- **Structured data**: Access nested configuration easily
- **Type-aware**: Numbers are numbers, not strings

### For Users
- **No changes needed**: Frontend submission remains the same
- **Better debugging**: Can easily inspect the JSON config
- **Flexible**: Can add custom hyperparameters

---

## Example: Complete RayJob Output

Here's what the backend generates for a typical XGBoost training job:

```yaml
apiVersion: ray.io/v1
kind: RayJob
metadata:
  name: xgboost-iris-test
  namespace: admin
  labels:
    app: xgboost-iris-test
    algorithm: xgboost
spec:
  entrypoint: python /home/ray/xgboost_train.py
  runtimeEnvYAML: |
    env_vars:
      TRAINING_CONFIG: |
        {
          "label_column": "target",
          "num_worker": 2,
          "run_name": "xgboost-iris-test",
          "s3": {
            "access_key": "...",
            "bucket": "training-data",
            "endpoint": "http://minio.kubeflow.svc:9000",
            "region": "us-east-1",
            "secret_key": "...",
            "train_key": "iris/train.csv"
          },
          "storage_path": "/home/ray/result-storage",
          "use_gpu": false,
          "xgboost": {
            "alpha": 0,
            "base_score": 0.5,
            "booster": "gbtree",
            "eta": 0.3,
            "eval_metric": ["rmse", "mae"],
            "max_depth": 6,
            "num_boost_round": 100,
            "objective": "reg:squarederror"
          }
        }
  rayClusterSpec:
    # ... cluster configuration
```

---

## Next Steps

1. ‚úÖ Backend updated to JSON format
2. ‚úÖ Tests passing
3. ‚úÖ Deployed to Kubernetes
4. üîÑ **Test with real job submission**
5. üìù Update training container to read JSON config
6. üìù Update documentation for users

---

## Troubleshooting

### Issue: Container can't parse TRAINING_CONFIG

**Check**:
```bash
kubectl get rayjob <job-name> -n <namespace> -o yaml | grep -A 100 "TRAINING_CONFIG"
```

**Verify**:
- JSON is properly formatted
- Indentation is correct
- No escaped characters causing issues

### Issue: Missing parameters in config

**Check backend logs**:
```bash
kubectl logs -n kubeflow -l app=ml-platform,component=backend --tail=50
```

Look for job creation logs showing the namespace and configuration.

---

**Version**: kubeflow-v1.2  
**Status**: ‚úÖ Production Ready  
**Tested**: Unit tests pass, integration test pending
